{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "## 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mutual_info_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# import Telco data into a pandas data frame\n",
    "df_telco = pd.read_csv('train (1) 1 (1).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA & Data Cleaning\n",
    "\n",
    "### Objectives: \n",
    "- understand the data \n",
    "- discover patterns and anomalies \n",
    "- check assumptions before performing further evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# concise summary of the data frame\n",
    "df_telco.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "- 20 columns, 3000 observations\n",
    "- no null values\n",
    "- data types: int64, float64, object\n",
    "- all columns have proper data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# check unique values of each column that aren't numerical\n",
    "for column in df_telco.columns:\n",
    "    if not (df_telco[column].dtype == 'int64' or df_telco[column].dtype == 'float64'):\n",
    "        print('{} - Unique Values: {}\\n'.format(column, df_telco[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Check number of unique states\n",
    "df_telco['state'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "- We have data covering all the 50 USA states, including Washington DC (federal district)\n",
    "- Even so, we only have 3 area_codes, and those are located in California only => the area code data seems erroneous and can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Removing area_code data from data set\n",
    "df_telco.drop('area_code', axis=1, inplace=True)\n",
    "df_telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# drop all the rows that have missing values (just in case, none found in our data set)\n",
    "df_telco.dropna(inplace=True)\n",
    "df_telco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization\n",
    "### 3.a Target Variable - Bar Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# create a figure\n",
    "fig = plt.figure(figsize=(10, 6)) \n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# proportion of observation of each class\n",
    "prop_response = df_telco['payment_delay'].value_counts(normalize=True)\n",
    "\n",
    "# create a bar plot showing the percentage of churn\n",
    "bar_plot = prop_response.plot(kind='bar', \n",
    "                               ax=ax,\n",
    "                               color=['springgreen','salmon'])\n",
    "\n",
    "\n",
    "# annotate each bar with its respective value\n",
    "for i, value in enumerate(prop_response):\n",
    "    bar_plot.text(i, value, f'{value:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# set title and labels\n",
    "ax.set_title('Target Variable Proportion',\n",
    "             fontsize=18, loc='center')\n",
    "ax.set_xlabel('payment delay',\n",
    "              fontsize=14)\n",
    "ax.set_ylabel('proportion of observations',\n",
    "              fontsize=14)\n",
    "ax.tick_params(rotation='auto')\n",
    "\n",
    "# eliminate frame\n",
    "spine_names = ('top', 'right', 'bottom', 'left')\n",
    "for spine_name in spine_names:\n",
    "    ax.spines[spine_name].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "- imbalanced data set (86.23% - no; 13.77% - yes)\n",
    "- this imbalance might lead to a large number of false negatives (Classifier Bias: Many machine learning algorithms are designed to optimize overall accuracy. In imbalanced datasets, where the majority class dominates, classifiers may prioritize optimizing accuracy by correctly classifying the majority class examples. As a result, they may perform poorly on the minority class, leading to false negatives.\n",
    "Class Separability: In imbalanced datasets, the minority class may be relatively rare and have less distinct patterns compared to the majority class. This makes it harder for classifiers to correctly identify and separate minority class instances, leading to false negatives.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b Plans Information\n",
    "Stacked percentage bar chart for telecom plans (voice mail & international)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def percentage_stacked_plot(columns_to_plot, super_title):\n",
    "    \n",
    "    '''\n",
    "    Prints a 100% stacked plot of the response variable (payment_delay) for independent variables of the list columns_to_plot.\n",
    "            Parameters:\n",
    "                    columns_to_plot (list of string): Names of the variables to plot\n",
    "                    super_title (string): Super title of the visualization\n",
    "            Returns:\n",
    "                    None\n",
    "    '''\n",
    "    \n",
    "    number_of_columns = 2\n",
    "    number_of_rows = math.ceil(len(columns_to_plot)/2)\n",
    "\n",
    "    # create a figure\n",
    "    fig = plt.figure(figsize=(12, 5 * number_of_rows)) \n",
    "    fig.suptitle(super_title, fontsize=22,  y=1)\n",
    " \n",
    "\n",
    "    # loop to each column name to create a subplot\n",
    "    for index, column in enumerate(columns_to_plot, 1):\n",
    "\n",
    "        # create the subplot\n",
    "        ax = fig.add_subplot(number_of_rows, number_of_columns, index)\n",
    "\n",
    "        # calculate the percentage of observations of the response variable for each group of the independent variable\n",
    "        # 100% stacked bar plot\n",
    "        prop_by_independent = pd.crosstab(df_telco[column], df_telco['payment_delay']).apply(lambda x: x/x.sum()*100, axis=1)\n",
    "\n",
    "        prop_by_independent.plot(kind='bar', ax=ax, stacked=True,\n",
    "                                 rot=0, color=['springgreen','salmon'])\n",
    "        \n",
    "        # Add annotations with exact values\n",
    "        for p in ax.patches:\n",
    "            width, height = p.get_width(), p.get_height()\n",
    "            x, y = p.get_xy() \n",
    "            ax.annotate(f'{height:.2f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "        \n",
    "\n",
    "        # set the legend in the upper right corner\n",
    "        ax.legend(loc=\"upper right\", bbox_to_anchor=(0.62, 0.5, 0.5, 0.5),\n",
    "                  title='Payment Delay', fancybox=True)\n",
    "\n",
    "        # set title and labels\n",
    "        ax.set_title('Proportion of observations by ' + column,\n",
    "                     fontsize=10, loc='center')\n",
    "\n",
    "        ax.tick_params(rotation='auto')\n",
    "\n",
    "        # eliminate the frame from the plot\n",
    "        spine_names = ('top', 'right', 'bottom', 'left')\n",
    "        for spine_name in spine_names:\n",
    "            ax.spines[spine_name].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# plans column names\n",
    "plan_columns = ['international_plan', 'voice_mail_plan']\n",
    "\n",
    "# stacked plot of demographic columns\n",
    "percentage_stacked_plot(plan_columns, 'Telecom Plans Information')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "- Observations suggest that users having an international plan have registered aprox 4 times more a payment delay as opposed to users without international plan.\n",
    "- In contrast, it seems that users having voice mail plan registered 2 times less payment delays vs. users without voice mail plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c Client Usage & Charge - Numerical Variables\n",
    "We are analysing via the following histogram plots the distribution of minutes, calls and charge for the observed categories in relation to our target variable (payment delay): \n",
    "- day \n",
    "- evening \n",
    "- night\n",
    "- international"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def histogram_plots(columns_to_plot, super_title):\n",
    "    \n",
    "    '''\n",
    "    Prints a histogram for each independent variable of the list columns_to_plot vs. the target variable (payment_delay).\n",
    "            Parameters:\n",
    "                    columns_to_plot (list of string): Names of the variables to plot\n",
    "                    super_title (string): Super title of the visualization\n",
    "            Returns:\n",
    "                    None\n",
    "    '''\n",
    "    # set number of rows and number of columns\n",
    "    number_of_columns = 2\n",
    "    number_of_rows = math.ceil(len(columns_to_plot)/2)\n",
    "\n",
    "    # create a figure\n",
    "    fig = plt.figure(figsize=(12, 5 * number_of_rows)) \n",
    "    fig.suptitle(super_title, fontsize=22,  y=1)\n",
    " \n",
    "\n",
    "    # loop to each demographic column name to create a subplot\n",
    "    for index, column in enumerate(columns_to_plot, 1):\n",
    "\n",
    "        # create the subplot\n",
    "        ax = fig.add_subplot(number_of_rows, number_of_columns, index)\n",
    "\n",
    "        # histograms for each class (normalized histogram)\n",
    "        df_telco[df_telco['payment_delay']=='no'][column].plot(kind='hist', ax=ax, density=True, \n",
    "                                                       alpha=0.5, color='springgreen', label='No')\n",
    "        df_telco[df_telco['payment_delay']=='yes'][column].plot(kind='hist', ax=ax, density=True,\n",
    "                                                        alpha=0.5, color='salmon', label='Yes')\n",
    "        \n",
    "        # set the legend in the upper right corner\n",
    "        ax.legend(loc=\"upper right\", bbox_to_anchor=(0.5, 0.5, 0.5, 0.5),\n",
    "                  title='payment delay', fancybox=True)\n",
    "\n",
    "        # set title and labels\n",
    "        ax.set_title('Distribution of ' + column,\n",
    "                     fontsize=16, loc='left')\n",
    "\n",
    "        ax.tick_params(rotation='auto')\n",
    "\n",
    "        # eliminate the frame from the plot\n",
    "        spine_names = ('top', 'right', 'bottom', 'left')\n",
    "        for spine_name in spine_names:\n",
    "            ax.spines[spine_name].set_visible(False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# define columns for analysis\n",
    "minutes_columns = ['total_day_minutes', 'total_eve_minutes', 'total_night_minutes', 'total_intl_minutes']\n",
    "# plot histograms \n",
    "histogram_plots(minutes_columns, 'Total Minutes per timespan by payment delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# define columns for analysis\n",
    "calls_columns = ['total_day_calls', 'total_eve_calls', 'total_night_calls', 'total_intl_calls']\n",
    "# plot histograms \n",
    "histogram_plots(calls_columns, 'Total Calls per timespan by payment delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# define columns for analysis\n",
    "charge_columns = ['total_day_charge', 'total_eve_charge', 'total_night_charge', 'total_intl_charge']\n",
    "# plot histograms\n",
    "histogram_plots(charge_columns, 'Total Charge per timespan by payment delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "- No substantial correlation observed other than a slightly pronounced payment delay for an increase in service usage (minutes) and charge respectively during daytime (upper left quadrants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d Client location (State) Information\n",
    "- generate a stacked bar plot to visualize the client's residency effects on payment delay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "def analyze_payment_delay_by_state(df):\n",
    "    '''\n",
    "    Analyze payment_delay regarding client location (state) by generating visualizations.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame containing the data.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    # Group data by state and payment_delay and get counts\n",
    "    state_payment_delay_counts = df.groupby(['state', 'payment_delay']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Calculate proportion of 'Yes' payment_delay for each state\n",
    "    state_payment_delay_proportions = state_payment_delay_counts['yes'] / state_payment_delay_counts.sum(axis=1)\n",
    "    state_payment_delay_proportions.sort_values(inplace=True)\n",
    "    \n",
    "    # Plot payment delay distribution for each state\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    state_payment_delay_counts.loc[state_payment_delay_proportions.index].plot(kind='bar', stacked=True, ax=ax, color=['springgreen', 'salmon'], edgecolor='none')\n",
    "    \n",
    "    # Annotate each bar with its respective percentage\n",
    "    for i, value in enumerate(state_payment_delay_proportions):\n",
    "        ax.text(i, state_payment_delay_counts.iloc[i].sum() + 0.02, f'{value:.1%}', ha='center', va='bottom')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_title('Payment Delay Distribution by State', fontsize=18)\n",
    "    ax.set_xlabel('State', fontsize=14)\n",
    "    ax.set_ylabel('Count', fontsize=14)\n",
    "    ax.legend(title='Payment Delay')\n",
    "\n",
    "    # eliminate the frame from the plot\n",
    "    spine_names = ('top', 'right', 'bottom', 'left')\n",
    "    for spine_name in spine_names:\n",
    "        ax.spines[spine_name].set_visible(False)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "analyze_payment_delay_by_state(df_telco)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "- significant variability is registered when cosidering client state (regional data)\n",
    "- at the lower end of the chart, we can observe that NE (Nebraska) or NM (New Mexico) a register a 3.9% and 5.1% payment delay, in contrast to TX (Texas) with 26%, or CA (California) with 26.9%\n",
    "- the data suggests that larger states, having a significant higher population, a larger market and more economical, cultural & demographical diveristy experience a higher proportion in payment delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.e Account Length (tenure) & Service Calls\n",
    "- Generating histograms to analyze the distribution of account length and number of customer service calls in relation to our target variable (payment delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "histogram_plots(['account_length', 'number_customer_service_calls'], 'Account length by payment delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION\n",
    "- Tenure (account length) does not seem to influence the target variable, as the distribution densities seem to overlap\n",
    "- A slight correlation between increased customer service calls and payment delays is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance (non numerical)\n",
    "\n",
    "### Mutual information — analysis of linear and nonlinear relationships\n",
    "\n",
    "Mutual information measures the mutual dependency between two variables based on entropy estimations. In machine learning, we are interested in evaluating the degree of dependency between each independent variable and the response variable. Higher values of mutual information show a higher degree of dependency which indicates that the independent variable will be useful for predicting the target.\n",
    "\n",
    "The Scikit-Learn library has implemented mutual information in the metrics package. The following code computes the mutual information score between each categorical variable of the data set and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# function that computes the mutual infomation score between a categorical serie and the column payment_delay\n",
    "def compute_mutual_information(categorical_serie):\n",
    "    return mutual_info_score(categorical_serie, df_telco['payment_delay'])\n",
    "\n",
    "# select categorial variables excluding the response variable \n",
    "# categorical_variables = df_telco.select_dtypes(include=object).drop('Churn', axis=1)\n",
    "categorical_variables = df_telco[['international_plan', 'voice_mail_plan', 'state']]\n",
    "\n",
    "# compute the mutual information score between each categorical variable and the target\n",
    "feature_importance = categorical_variables.apply(compute_mutual_information).sort_values(ascending=False)\n",
    "\n",
    "# visualize feature importance\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "- we can observe that international_plan and state information have a stronger relation to the target as opposed to voice_mail_plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering / Data Prep\n",
    "- Feature engineering is the process of extracting features from the data and transforming them into a format that is suitable for the machine learning model.\n",
    "- Most machine learning algorithms require numerical values; therefore, all categorical attributes available in the dataset should be encoded into numerical labels before training the model. In addition, we need to transform numeric columns into a common scale. This will prevent that the columns with large values dominate the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.a Label Encoding\n",
    "Label encoding is used to replace categorical values with numerical values. This encoding replaces every category with a numerical label. Binary variables for our customer plans are replaced below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_telco_prep = df_telco.copy()\n",
    "\n",
    "# label encoding (binary variables)\n",
    "label_encoding_columns = ['international_plan', 'voice_mail_plan', 'payment_delay']\n",
    "\n",
    "# encode categorical binary features using label encoding\n",
    "for column in label_encoding_columns:\n",
    "    df_telco_prep[column] = df_telco_prep[column].map({'yes': 1, 'no': 0})\n",
    "\n",
    "df_telco_prep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b Target Encoding (Mean Encoding)\n",
    "Helps capture the relationship between the categories and the target variable by encoding each category with the mean of the target variable for that category. This technique can work well for classification problems, especially when there's a strong correlation between the categorical variable and the target variable.\n",
    "We will implement target encoding for the 'state' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 1. Split the DataFrame into features (X) and target variable (y)\n",
    "X = df_telco_prep.drop(columns=['payment_delay'])  # Features\n",
    "y = df_telco_prep['payment_delay']  # Target variable\n",
    "\n",
    "# 2. Initialize the TargetEncoder\n",
    "encoder = TargetEncoder(cols=['state'])\n",
    "\n",
    "unique_states = df_telco_prep['state'].unique()\n",
    "\n",
    "# 3. Fit and transform the 'state' column using target encoding\n",
    "X['state_encoded'] = encoder.fit_transform(X['state'], y)\n",
    "\n",
    "# 4. Drop the original 'state' column\n",
    "X.drop(columns=['state'], inplace=True)\n",
    "\n",
    "# Now, df_telco_prep = X, & contains the target-encoded 'state' column as 'state_encoded'\n",
    "df_telco_prep = X.copy(deep=True)\n",
    "df_telco_prep['payment_delay'] = y\n",
    "df_telco_prep\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping state names to their encoded values\n",
    "state_encoding_dict = dict(zip(unique_states, X['state_encoded'].unique()))\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(state_encoding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis\n",
    "- Correlation analysis is a statistical technique used to measure the strength and direction of the relationship between two quantitative variables. It helps in understanding how changes in one variable are associated with changes in another variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.a Correlation Matrix for Target Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Compute correlation matrix for target variables\n",
    "target_corr_matrix = df_telco_prep.corrwith(df_telco_prep['payment_delay']).sort_values(ascending=False)\n",
    "\n",
    "# Print correlation matrix for target variables\n",
    "print(\"Correlation Matrix for Target Variables:\")\n",
    "print(target_corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETAION:\n",
    "- each correlation coefficient is indicating the strength and direction of the linear relationship between payment_delay and the other variables. Positive coefficients suggest a positive relationship, negative coefficients suggest a negative relationship, and coefficients close to 0 suggest little to no linear relationship.\n",
    "- relevant variables are thus:\n",
    "    - payment_delay                    \n",
    "    - international_plan              \n",
    "    - total_day_minutes                \n",
    "    - total_day_charge                 \n",
    "    - number_customer_service_calls    \n",
    "    - state_encoded\n",
    "- considering all previous analysis(Data Visualization chapter also) and previous output, we can remove the other irrelevant features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_telco_prep.drop(columns=['total_eve_minutes','total_eve_charge','total_intl_charge','total_intl_minutes','total_night_minutes','total_night_charge','account_length','total_day_calls','total_night_calls','total_eve_calls','total_intl_calls'], inplace=True)\n",
    "df_telco_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.b Correlation Matrix between Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Compute correlation matrix for features\n",
    "feature_corr_matrix = df_telco_prep.drop(columns=['payment_delay']).corr()\n",
    "\n",
    "# Plot correlation matrix as heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(feature_corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix between Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "- Total day minutes and charge are again seen as correlated and one of them can be droped.\n",
    "- Number of vmail messages with vmail plan is also strongly correlated and we can drop the vmail messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_telco_prep.drop(columns=['total_day_minutes', 'number_vmail_messages'], inplace=True)\n",
    "df_telco_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Building\n",
    "## A) Data Preprocessing - Normalization\n",
    "Data Normalization is a common practice in machine learning which consists of transforming numeric columns to a common scale. In machine learning, some feature values differ from others multiple times. The features with higher values will dominate the learning process; however, it does not mean those variables are more important to predict the target. Data normalization transforms multiscaled data to the same scale. After normalization, all variables have a similar influence on the model, improving the stability and performance of the learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# min-max normalization (numeric variables)\n",
    "min_max_columns = ['total_day_charge', 'number_customer_service_calls']\n",
    "\n",
    "# scale numerical variables using min max scaler\n",
    "for column in min_max_columns:\n",
    "        # minimum value of the column\n",
    "        min_column = df_telco_prep[column].min()\n",
    "        # maximum value of the column\n",
    "        max_column = df_telco_prep[column].max()\n",
    "        # min max scaler\n",
    "        df_telco_prep[column] = (df_telco_prep[column] - min_column) / (max_column - min_column)\n",
    "\n",
    "df_telco_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "# X is the feature matrix and y is the target variable\n",
    "X = df_telco_prep.drop(columns='payment_delay').copy(deep=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"X_train:\")\n",
    "print(X_train.shape)\n",
    "X_train.info()\n",
    "print(\"-------------------------\")\n",
    "\n",
    "print(\"X_test:\")\n",
    "print(X_test.shape)\n",
    "X_test.info()\n",
    "print(\"-------------------------\")\n",
    "\n",
    "print(\"y_train:\")\n",
    "print(y_train.shape)\n",
    "y_train.info()\n",
    "print(\"-------------------------\")\n",
    "\n",
    "print(\"y_test:\")\n",
    "print(y_test.shape)\n",
    "y_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def create_models(seed=2):\n",
    "    '''\n",
    "    Create a list of machine learning models.\n",
    "            Parameters:\n",
    "                    seed (integer): random seed of the models\n",
    "            Returns:\n",
    "                    models (list): list containing the models\n",
    "    '''\n",
    "\n",
    "    models = []\n",
    "    models.append(('dummy_classifier', DummyClassifier(random_state=seed, strategy='most_frequent')))\n",
    "    models.append(('k_nearest_neighbors', KNeighborsClassifier()))\n",
    "    models.append(('logistic_regression', LogisticRegression(random_state=seed)))\n",
    "    models.append(('support_vector_machines', SVC(random_state=seed)))\n",
    "    models.append(('random_forest', RandomForestClassifier(random_state=seed)))\n",
    "    models.append(('gradient_boosting', GradientBoostingClassifier(random_state=seed)))\n",
    "    \n",
    "    return models\n",
    "\n",
    "# create a list with all the algorithms we are going to assess\n",
    "models = create_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matthews Correlation Coefficient (MCC) is a metric that can be useful, especially for imbalanced datasets. MCC takes into account all four values of the confusion matrix (true positives, true negatives, false positives, false negatives) and is particularly helpful when the classes are imbalanced.\n",
    "\n",
    "MCC ranges from -1 to 1, where 1 indicates perfect prediction, 0 indicates random prediction, and -1 indicates total disagreement between prediction and observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# test the accuracy of each model using default hyperparameters\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    # fit the model with the training data\n",
    "    model.fit(X_train, y_train).predict(X_test)\n",
    "    # make predictions with the testing data\n",
    "    predictions = model.predict(X_test)\n",
    "    # calculate accuracy \n",
    "    # accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    accuracy = matthews_corrcoef(y_test, predictions)\n",
    "\n",
    "    # append the model name and the accuracy to the lists\n",
    "    results.append(accuracy)\n",
    "    names.append(name)\n",
    "    # print classifier accuracy\n",
    "    print('Classifier: {}, Accuracy: {})'.format(name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected Algorithm => Random Forest\n",
    "An ensemble learning method based on decision trees. It trains multiple decision trees on random subsets of the data and features, then aggregates their predictions to make final predictions. It's known for its robustness, ability to handle large datasets, and feature importance ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Hyperparameter tuning - Improving Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the MCC scorer\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV with MCC as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring=mcc_scorer, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_mcc = matthews_corrcoef(y_test, best_rf.predict(X_test))\n",
    "print(\"Test MCC precision after hyperparameter tuning:\")\n",
    "print(\"MCC precision score (scale -1 to 1):\", test_mcc)\n",
    "mcc_score_scaled = (test_mcc + 1) / 2\n",
    "print(\"Precision score (normal scale 0-1):\", mcc_score_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# make the predictions\n",
    "random_search_predictions = best_rf.predict(X_test)\n",
    "\n",
    "# construct the confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, random_search_predictions)\n",
    "\n",
    "# visualize the confusion matrix\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Prediction Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# # Prediction Demo\n",
    "new_data_json = {\n",
    "  \"state\": [\"TN\"],\n",
    "  \"account_length\": [80],\n",
    "  \"area_code\": [\"area_code_415\"],\n",
    "  \"international_plan\": [\"yes\"],\n",
    "  \"voice_mail_plan\": [\"no\"],\n",
    "  \"number_vmail_messages\": [0],\n",
    "  \"total_day_minutes\": [276.5],\n",
    "  \"total_day_calls\": [122],\n",
    "  \"total_day_charge\": [47.01],\n",
    "  \"total_eve_minutes\": [195.6],\n",
    "  \"total_eve_calls\": [79],\n",
    "  \"total_eve_charge\": [16.63],\n",
    "  \"total_night_minutes\": [210.3],\n",
    "  \"total_night_calls\": [78],\n",
    "  \"total_night_charge\": [9.46],\n",
    "  \"total_intl_minutes\": [7.2],\n",
    "  \"total_intl_calls\": [3],\n",
    "  \"total_intl_charge\": [1.94],\n",
    "  \"number_customer_service_calls\": [1],\n",
    "}\n",
    "\n",
    "\n",
    "df_new_data = pd.DataFrame(new_data_json)\n",
    "\n",
    "def encode_new_data(data):\n",
    "    encoded_data = data.copy()\n",
    "\n",
    "    # drop unused columns\n",
    "    columns_to_drop = ['area_code', 'total_day_minutes', 'total_eve_minutes','total_eve_charge','total_intl_charge','total_intl_minutes','total_night_minutes','total_night_charge','account_length','total_day_calls','total_night_calls','total_eve_calls','total_intl_calls','number_vmail_messages']\n",
    "    for column in encoded_data.columns.tolist():\n",
    "        if column in columns_to_drop:\n",
    "            encoded_data.drop(columns=column, inplace=True)\n",
    "   \n",
    "    # label encoding (binary variables)\n",
    "    label_encoding_columns = ['international_plan', 'voice_mail_plan']\n",
    "    for column in label_encoding_columns:\n",
    "        encoded_data[column] = encoded_data[column].map({'yes': 1, 'no': 0})\n",
    "\n",
    "    # map state categorical value to its numerical mean encoding\n",
    "    global state_encoding_dict\n",
    "    state_name = encoded_data.at[0, 'state']\n",
    "    encoded_data.drop(columns=['state'], inplace=True)\n",
    "    encoded_data.loc[0, 'state_encoded'] = state_encoding_dict[state_name]\n",
    "\n",
    "    return encoded_data\n",
    "\n",
    "\n",
    "df_encoded_new_data = encode_new_data(df_new_data)\n",
    "print(df_encoded_new_data)\n",
    "\n",
    "payment_delay_prediction = best_rf.predict(df_encoded_new_data)\n",
    "print(type(payment_delay_prediction))\n",
    "\n",
    "if any(payment_delay_prediction) == 1:\n",
    "    print(\"Client Payment Delay Prediction: True\")\n",
    "else:\n",
    "    print(\"Client Payment Delay Prediction: False\")\n",
    "\n",
    "\n",
    "# Print the precision score\n",
    "print(\"Precision Score:\", mcc_score_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G) Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/opt/python@3.12/libexec/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('best_rf_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_rf, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
